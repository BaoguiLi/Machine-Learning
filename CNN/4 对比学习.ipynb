{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "          Identity-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "             ReLU-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "             ReLU-21          [-1, 128, 16, 16]               0\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "           Conv2d-24          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
      "             ReLU-26          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-27          [-1, 128, 16, 16]               0\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "             ReLU-30          [-1, 128, 16, 16]               0\n",
      "           Conv2d-31          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "             ReLU-33          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
      "           Conv2d-35            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "             ReLU-37            [-1, 256, 8, 8]               0\n",
      "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
      "           Conv2d-40            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 8, 8]             512\n",
      "             ReLU-42            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-43            [-1, 256, 8, 8]               0\n",
      "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
      "             ReLU-46            [-1, 256, 8, 8]               0\n",
      "           Conv2d-47            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
      "             ReLU-49            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-50            [-1, 256, 8, 8]               0\n",
      "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-53            [-1, 512, 4, 4]               0\n",
      "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-58            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-59            [-1, 512, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-66            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 16.00\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 58.64\n",
      "----------------------------------------------------------------\n",
      "Model weights loaded from E:\\shuyang\\代码文件\\教学课件\\面试班\\25复试班\\进阶项目\\CNN\\model_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 391/391 [01:12<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Contrastive Loss: 3.2421, Time taken: 72.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 391/391 [01:13<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Contrastive Loss: 2.6218, Time taken: 73.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 391/391 [01:12<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Contrastive Loss: 2.4693, Time taken: 72.79 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 391/391 [01:12<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Contrastive Loss: 2.3679, Time taken: 72.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 391/391 [01:12<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Contrastive Loss: 2.3050, Time taken: 72.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 391/391 [01:12<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Contrastive Loss: 2.2593, Time taken: 72.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 391/391 [01:12<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Contrastive Loss: 2.2250, Time taken: 72.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 391/391 [01:12<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Contrastive Loss: 2.1736, Time taken: 72.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 391/391 [01:11<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Contrastive Loss: 2.1488, Time taken: 71.95 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 391/391 [01:11<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Contrastive Loss: 2.1425, Time taken: 71.83 seconds\n",
      "Contrastive model weights saved to E:\\shuyang\\代码文件\\教学课件\\面试班\\25复试班\\进阶项目\\CNN\\contrastive_model_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set: 100%|██████████| 100/100 [00:02<00:00, 42.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss after contrastive learning: 3.2534, Test Acc: 24.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 检查 GPU 可用性\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 对比学习数据增强\n",
    "contrastive_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 测试集数据预处理\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 自定义 collate_fn 函数\n",
    "def custom_collate(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    return images, default_collate(labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 加载训练集用于对比学习（不进行转换）\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=None)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=128, shuffle=True, num_workers=0, collate_fn=custom_collate)\n",
    "\n",
    "    # 加载测试集\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 定义类别名称\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # 获取当前运行文件所在的文件夹路径\n",
    "    import os\n",
    "    current_dir = os.getcwd()\n",
    "    # 设置 TORCH_HOME 环境变量为当前文件夹\n",
    "    os.environ['TORCH_HOME'] = current_dir\n",
    "\n",
    "    # 加载预训练模型\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "    # 修改全连接层以适应 CIFAR - 10 数据集\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()  # 移除原模型中的 maxpool\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 打印模型的结构信息\n",
    "    summary(model, (3, 32, 32))\n",
    "\n",
    "    # 模型权重文件路径\n",
    "    model_weights_path = r'E:\\shuyang\\代码文件\\教学课件\\面试班\\25复试班\\进阶项目\\CNN\\model_weights.pth'\n",
    "\n",
    "    # 加载之前保存的模型权重\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_weights_path))\n",
    "        print(f'Model weights loaded from {model_weights_path}')\n",
    "    except FileNotFoundError:\n",
    "        print(f'Weight file {model_weights_path} not found.')\n",
    "        exit(1)\n",
    "\n",
    "    # 对比学习超参数\n",
    "    temperature = 0.1\n",
    "    contrastive_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # 优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # InfoNCE 损失函数\n",
    "    def info_nce_loss(features, temperature=0.1):\n",
    "        batch_size = features.shape[0] // 2\n",
    "        labels = torch.cat([torch.arange(batch_size) for i in range(2)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        similarity_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
    "        logits = logits / temperature\n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    # 对比学习训练\n",
    "    for epoch in range(contrastive_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        for i, (images, _) in enumerate(tqdm(trainloader, desc=f'Epoch {epoch + 1}/{contrastive_epochs}')):\n",
    "            # 对每个样本进行两次不同的数据增强\n",
    "            images1 = torch.stack([contrastive_transform(img) for img in images]).to(device)\n",
    "            images2 = torch.stack([contrastive_transform(img) for img in images]).to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            features1 = model(images1)\n",
    "            features2 = model(images2)\n",
    "            features = torch.cat([features1, features2], dim=0)\n",
    "\n",
    "            # 计算对比损失\n",
    "            loss = info_nce_loss(features, temperature)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        end_time = time.time()\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        print(f'Epoch {epoch + 1}/{contrastive_epochs}, Contrastive Loss: {epoch_loss:.4f}, Time taken: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "    # 保存对比学习后的模型权重\n",
    "    contrastive_model_weights_path = r'E:\\shuyang\\代码文件\\教学课件\\面试班\\25复试班\\进阶项目\\CNN\\contrastive_model_weights.pth'\n",
    "    # torch.save(model.state_dict(), contrastive_model_weights_path)\n",
    "    # print(f'Contrastive model weights saved to {contrastive_model_weights_path}')\n",
    "\n",
    "    # 评估对比学习后的模型\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=\"Inference on test set\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_val_loss = val_running_loss / len(testloader)\n",
    "    epoch_val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    # 打印推理结果\n",
    "    print(f'Test Loss after contrastive learning: {epoch_val_loss:.4f}, Test Acc: {epoch_val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
